---
title_fa:
title: "A Tutorial on Hunting Statistical Significance by Chasing N"
layout: post_en
date: '2016-09-28'
date_fa:
comments: true
categories: article
link: http://journal.frontiersin.org/article/10.3389/fpsyg.2016.01444/full
doi: 10.3389/fpsyg.2016.01444
pmid: 
tags:
- Statistics
- p-value
- p-hacking
- Methodology
- Research
---

> *Szucs, D. (2016). A tutorial on hunting statistical significance by chasing N. Frontiers in Psychology, 7, 1444.* ([Link](http://journal.frontiersin.org/article/10.3389/fpsyg.2016.01444/full))


There is increasing concern about the replicability of studies in psychology and cognitive neuroscience. Hidden data dredging (also called p-hacking) is a major contributor to this crisis because it substantially increases Type I error resulting in a much larger proportion of false positive findings than the usually expected 5%. In order to build better intuition to avoid, detect and criticize some typical problems, here I systematically illustrate the large impact of some easy to implement and so, perhaps frequent data dredging techniques on boosting false positive findings. I illustrate several forms of two special cases of data dredging. First, researchers may violate the data collection stopping rules of null hypothesis significance testing by repeatedly checking for statistical significance with various numbers of participants...

<!--more-->

Second, researchers may group participants post hoc along potential but unplanned independent grouping variables. The first approach ‘hacks’ the number of participants in studies, the second approach ‘hacks’ the number of variables in the analysis. I demonstrate the high amount of false positive findings generated by these techniques with data from true null distributions. I also illustrate that it is extremely easy to introduce strong bias into data by very mild selection and re-testing. Similar, usually undocumented data dredging steps can easily lead to having 20–50%, or more false positives.
